# -*- coding: utf-8 -*-
"""hw3p2-model3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZW1KBxX96AgVARnnVCw64vUprd8NtBQ-

## Kaggle Setup
"""

# !nvidia-smi
# !pip install --upgrade kaggle

# mkdir .kaggle

# import json
# token = {"username":"kexinzhangcmu","key":"91f327ebd62f2d3cfeb09f0344748606"}

# with open('/content/.kaggle/kaggle.json', 'w') as file:
#       json.dump(token, file)

# # Commented out IPython magic to ensure Python compatibility.
# !chmod 600 /content/.kaggle/kaggle.json
# !mkdir ~/.kaggle
# !cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json
# !kaggle config set -n path -v /content/
# !kaggle competitions download -c 11-785-fall-20-homework-3
# # %cd competitions/11-785-fall-20-homework-3
# !unzip \*.zip
# !rm -rf *.zip

"""## Install CTC Decode"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
# !git clone --recursive https://github.com/parlance/ctcdecode.git
# !pip install wget
# %cd ctcdecode
# !pip install .
# %cd ..

"""## Mount GDrive"""

from google.colab import drive
drive.mount('/content/gdrive')

# ls

"""## Imports"""

!cp /content/competitions/11-785-fall-20-homework-3/phoneme_list.py /content/

import sys
sys.path.append("/content/competitions/11-785-fall-20-homework-3/")

import torch
from torch import nn
from torch.nn.utils.rnn import *
from phoneme_list import N_PHONEMES, PHONEME_LIST, PHONEME_MAP
from torch.optim.lr_scheduler import StepLR, MultiplicativeLR, CosineAnnealingLR

from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import time

torch.__version__

from tqdm import tqdm

cuda = torch.cuda.is_available()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

"""## Load Data"""

import numpy as np
import torch

DATA_PATH = "/content/competitions/11-785-fall-20-homework-3/"

def load_data(data_path=DATA_PATH):
    """load data"""
    train = np.load(data_path + "train.npy",allow_pickle=True)
    train_labels = np.load(data_path + "train_labels.npy",allow_pickle=True)
    dev = np.load(data_path + 'dev.npy', allow_pickle=True)
    dev_labels = np.load(data_path + 'dev_labels.npy', allow_pickle=True)
    
    return train, train_labels, dev, dev_labels 


train, train_labels, dev, dev_labels = load_data(DATA_PATH)
print("training samples:", train.shape[0], "dev samples:", dev.shape[0])

def load_test_data(data_path=DATA_PATH):
    """load data"""
    test = np.load(data_path + "test.npy",allow_pickle=True)
    
    return test
test = load_test_data()
print("test samples:", test.shape)

train_batch_size = 64
dev_batch_size = 64

class hw3Dataset(Dataset):
    def __init__(self, X, Y):
        assert(len(X) == len(Y))
        self.X_lens = torch.LongTensor([len(x) for x in X])
        train_tensors = [torch.FloatTensor(x).float() for x in X]
        self.X = pad_sequence(train_tensors, batch_first=True)

        self.Y_lens = torch.LongTensor([len(y) for y in Y])
        labels_tensors = [torch.LongTensor(y + 1) for y in Y] # add 1
        self.Y = pad_sequence(labels_tensors, batch_first=True)

        print("# of examples:", self.X.shape, "//", self.Y.shape)
        print("max:", self.Y.max(), "min:", self.Y.min())
    
    def __len__(self):
        return len(self.Y)
    
    def __getitem__(self, index):
        X = self.X[index]
        Y = self.Y[index]
        X_lens = self.X_lens[index]
        Y_lens = self.Y_lens[index]                
        return X, X_lens, Y, Y_lens
    

num_workers = 4

train_dataset = hw3Dataset(train, train_labels)
train_loader_args = dict(shuffle = True, batch_size = train_batch_size,
                        num_workers = num_workers, pin_memory = True, drop_last = False)
train_loader = DataLoader(train_dataset, **train_loader_args)

dev_dataset = hw3Dataset(dev, dev_labels)
dev_loader_args = dict(shuffle = False, batch_size = dev_batch_size,
                        num_workers = num_workers, pin_memory = True, drop_last = False)
dev_loader = DataLoader(dev_dataset, **dev_loader_args)

# generating true labels
Y_true_list = []
Y_lens_true_list = []

for idx, (X, X_lens, Y, Y_lens) in tqdm(enumerate(dev_loader)):
    X, X_lens, Y, Y_lens = X.to(device), X_lens.to(device), Y.to(device), Y_lens.to(device)
    Y_true_list.extend(Y.cpu().numpy())
    Y_lens_true_list.extend(Y_lens.cpu().numpy())

true_string_list = []
for y_true, lens_true in tqdm(zip(Y_true_list, Y_lens_true_list)):
    true_seq = y_true[:lens_true]
    true_string = ''.join(PHONEME_MAP[i] for i in true_seq)
    true_string_list.append(true_string)

class Model(nn.Module):
    def __init__(self, hidden_size, embed_size = 13, out_vocab = 42):
        super(Model, self).__init__()
        self.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, 
                            bidirectional=True, num_layers=5)
        self.output = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size * 2),
            # nn.ReLU()
            nn.LeakyReLU(),
            nn.Dropout(0.1),
            # nn.BatchNorm1d(hidden_size),
            nn.Linear(hidden_size * 2, out_vocab))

    
    def forward(self, X, lengths):
        packed_X = pack_padded_sequence(X, lengths, enforce_sorted=False, batch_first = True)
        packed_out = self.lstm(packed_X)[0]
        out, out_lens = pad_packed_sequence(packed_out)
        # Log softmax after output layer is required since`nn.CTCLoss` expects log probabilities.
        out = self.output(out).log_softmax(2)
        return out, out_lens

# load model
model = Model(512)
model.train()
model.to(device)

criterion = nn.CTCLoss()

# min_val_loss = float(model_file[-4:])
save_path = "/content/gdrive/My Drive/11685deeplearning/hw3p2/"
model_name = "wider_2_baseline"

def validate(model, data_loader, criterion, device, min_val_loss):
    model.eval()
    val_loss = []
    with torch.no_grad():
        for idx, (X, X_lens, Y, Y_lens) in enumerate(data_loader):

            X, X_lens, Y, Y_lens = X.to(device), X_lens.to(device), Y.to(device), Y_lens.to(device)

            optimizer.zero_grad()
            out, out_lens = model(X, X_lens.cpu())
            loss = criterion(out, Y, out_lens, Y_lens)
            val_loss.append(loss.item())

            del X, X_lens, Y, Y_lens

    model.train()
    mean_val_loss = np.mean(val_loss)

    if mean_val_loss < min_val_loss:
        print("save model!")
        torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict()}, 
        save_path + model_name + "_" + str(epoch) + "_" + "{:.2f}".format(mean_val_loss))

        min_val_loss = val_loss
    return mean_val_loss

"""#### Multiplicative LR"""

weightDecay = 1e-5
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay = weightDecay)
# MultiplicativeLR
lmbda = lambda epoch: 0.85
scheduler = MultiplicativeLR(optimizer, lr_lambda=lmbda)

start = time.time()
numEpochs = 10 # TODO: change num of epochs

for epoch in range(numEpochs):
    for idx, (X, X_lens, Y, Y_lens) in enumerate(train_loader):
        model.train()
        X, X_lens, Y, Y_lens = X.to(device), X_lens.to(device), Y.to(device), Y_lens.to(device)

        optimizer.zero_grad()
        out, out_lens = model(X, X_lens.cpu())
        loss = criterion(out, Y, out_lens, Y_lens)

        del X, X_lens, Y, Y_lens
        del out, out_lens
        torch.cuda.empty_cache()

        loss.backward()
        optimizer.step()

        if idx % 10 == 9:
            print('Epoch: {}/Batch: {}\t Train Loss: {:.4f}\ttime: {}sec'.format(epoch + 1, idx + 1,
                                                                            loss.item(),
                                                                            int(time.time() - start)))
            start = time.time()
            # print("Learning rate: ", scheduler.get_last_lr()[0])

        torch.cuda.empty_cache()
        # scheduler.step() # TODO: uncomment if scheduler = cosineAnnealing
        
    val_loss = validate(model, dev_loader, criterion, device, min_val_loss)
    print('Epoch: {}\tTrain Loss: {:.4f}\tVal Loss: {:.4f}'.format(epoch + 1,loss.item(), val_loss))

    scheduler.step()
    print("Learning rate: ", scheduler.get_last_lr()[0])

weightDecay = 1e-5
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = weightDecay)
# MultiplicativeLR
lmbda = lambda epoch: 0.85
scheduler = MultiplicativeLR(optimizer, lr_lambda=lmbda)

start = time.time()
numEpochs = 10 # TODO: change num of epochs

for epoch in range(numEpochs):
    for idx, (X, X_lens, Y, Y_lens) in enumerate(train_loader):
        model.train()
        X, X_lens, Y, Y_lens = X.to(device), X_lens.to(device), Y.to(device), Y_lens.to(device)

        optimizer.zero_grad()
        out, out_lens = model(X, X_lens.cpu())
        loss = criterion(out, Y, out_lens, Y_lens)

        del X, X_lens, Y, Y_lens
        del out, out_lens
        torch.cuda.empty_cache()

        loss.backward()
        optimizer.step()

        if idx % 10 == 9:
            print('Epoch: {}/Batch: {}\t Train Loss: {:.4f}\ttime: {}sec'.format(epoch + 1, idx + 1,
                                                                            loss.item(),
                                                                            int(time.time() - start)))
            start = time.time()
            # print("Learning rate: ", scheduler.get_last_lr()[0])

        torch.cuda.empty_cache()
        # scheduler.step() # TODO: uncomment if scheduler = cosineAnnealing
        
    val_loss = validate(model, dev_loader, criterion, device, min_val_loss)
    print('Epoch: {}\tTrain Loss: {:.4f}\tVal Loss: {:.4f}'.format(epoch + 1,loss.item(), val_loss))
    # print_abit(out, out_lens)

    scheduler.step()
    print("Learning rate: ", scheduler.get_last_lr()[0])

"""#### CosineAnnealing LR"""

weightDecay = 5e-6
optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay = weightDecay)
# CosineAnnealingLR
scheduler = CosineAnnealingLR(optimizer, len(train_loader), eta_min = 1e-7)

start = time.time()
min_val_loss = 0.6
numEpochs = 5 # TODO: change num of epochs

for epoch in range(numEpochs):
    for idx, (X, X_lens, Y, Y_lens) in enumerate(train_loader):
        model.train()
        X, X_lens, Y, Y_lens = X.to(device), X_lens.to(device), Y.to(device), Y_lens.to(device)

        optimizer.zero_grad()
        out, out_lens = model(X, X_lens.cpu())
        loss = criterion(out, Y, out_lens, Y_lens)

        del X, X_lens, Y, Y_lens
        del out, out_lens
        torch.cuda.empty_cache()

        loss.backward()
        optimizer.step()

        if idx % 10 == 9:
            print('Epoch: {}/Batch: {}\t Train Loss: {:.4f}\ttime: {}sec'.format(epoch + 1, idx + 1,
                                                                            loss.item(),
                                                                            int(time.time() - start)))
            start = time.time()

        torch.cuda.empty_cache()
        scheduler.step() # TODO: uncomment if scheduler = cosineAnnealing
        
    val_loss = validate(model, dev_loader, criterion, device, min_val_loss)
    print('Epoch: {}\tTrain Loss: {:.4f}\tVal Loss: {:.4f}'.format(epoch + 1,loss.item(), val_loss))

    # scheduler.step()
    print("Learning rate: ", scheduler.get_last_lr()[0])

    print('Reset scheduler')
    scheduler = CosineAnnealingLR(optimizer, len(train_loader))

"""## Evaluate"""

# !pip install python-Levenshtein

"""
decode
"""
from ctcdecode import CTCBeamDecoder
import os
import pandas as pd

from Levenshtein import distance as levenshtein_distance
from tqdm import tqdm

dev_beam_width = 20
submit_beam_width = 100

# load model
model = Model(512)
model_file = "/content/gdrive/My Drive/11685deeplearning/hw3p2/wider_2_baseline_4_0.49"
temp = torch.load(model_file)
model.load_state_dict(temp['model_state_dict'])
model.to(device)

"""
dev distance
"""

def validate_distance(model, dev_loader, criterion, device, dev_beam_width = dev_beam_width):
    decoder = CTCBeamDecoder(PHONEME_LIST, beam_width=dev_beam_width, 
                            num_processes=os.cpu_count(), log_probs_input=True)

    model.eval()

    Y_pred_list = []
    Y_lens_pred_list = []
    # loop the dev data loader and get beam search result
    with torch.no_grad():
        for idx, (X, X_lens, Y, Y_lens) in tqdm(enumerate(dev_loader)):
            X, X_lens, Y, Y_lens = X.to(device), X_lens.to(device), Y.to(device), Y_lens.to(device)
            out, out_lens = model(X, X_lens.cpu())
            loss = criterion(out, Y, out_lens, Y_lens)

            test_Y, _, _, test_Y_lens = decoder.decode(out.transpose(0, 1), out_lens)
            Y_pred_list.extend(test_Y[:,0,:].cpu().numpy())
            Y_lens_pred_list.extend(test_Y_lens[:,0].cpu().numpy())

    assert(len(Y_pred_list) == len(Y_lens_pred_list) == len(Y_true_list) == len(Y_lens_true_list))

    # calculate distance between true label
    pred_string_list = [] # string list for submission
    distance = [] # distance list for evaluation
    for idx, (y_pred, lens_pred) in tqdm(enumerate(zip(Y_pred_list,Y_lens_pred_list))):
        best_seq = y_pred[:lens_pred]
        pred_string = ''.join(PHONEME_MAP[i] for i in best_seq)
        pred_string_list.append(pred_string)

        distance.append(levenshtein_distance(pred_string, true_string_list[idx]))

    print("average distance: ", np.mean(distance))

validate_distance(model, dev_loader, criterion, device)

"""## Make submissions"""

# test data loader
test_labels = np.zeros((test.shape[0], 1))
test_dataset = hw3Dataset(test, test_labels)
test_loader_args = dict(shuffle = False, batch_size = 128,
                        num_workers = num_workers, pin_memory = True)
test_loader = DataLoader(test_dataset, **test_loader_args)

"""
submit
"""


def submit_csv(model, test_loader, criterion, device, submit_beam_width = submit_beam_width):
    model.eval()
    Y_pred_list = []
    Y_lens_pred_list = []


    from tqdm import tqdm
    decoder = CTCBeamDecoder(PHONEME_LIST, beam_width=submit_beam_width, 
                            num_processes=os.cpu_count(), log_probs_input=True)
    # loop the dev data loader and get beam search result
    with torch.no_grad():
        for idx, (X, X_lens, _, _) in tqdm(enumerate(test_loader)):
            X, X_lens = X.to(device), X_lens.to(device)
            out, out_lens = model(X, X_lens.cpu())

            test_Y, _, _, test_Y_lens = decoder.decode(out.transpose(0, 1), out_lens)
            Y_pred_list.extend(test_Y[:,0,:].cpu().numpy())
            Y_lens_pred_list.extend(test_Y_lens[:,0].cpu().numpy())

    assert(len(Y_pred_list) == len(Y_lens_pred_list))

    # calculate distance between true label
    pred_string_list = [] # string list for submission
    distance = [] # distance list for evaluation
    for idx, (y_pred, lens_pred) in tqdm(enumerate(zip(Y_pred_list,Y_lens_pred_list))):
        best_seq = y_pred[:lens_pred]
        pred_string = ''.join(PHONEME_MAP[i] for i in best_seq)
        pred_string_list.append(pred_string)

    df = pd.DataFrame(enumerate(pred_string_list), columns = ['id', 'label'])
    df.to_csv("submission_hw3p2.csv", index=False)

submit_csv(model, test_loader, criterion, device)